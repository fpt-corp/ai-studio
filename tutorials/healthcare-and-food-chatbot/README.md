# Healthcare & Food Chatbot

## Overview

**Healthcare & Food Chatbot** demonstrates how a **Large Language Model (LLM)** can serve as an intelligent assistant for **healthy eating guidance and regional cuisine exploration**, helping users **learn about dishes, understand nutritional benefits**, and **interactively explore healthcare-related conversations** around food through natural dialogue.

Powered by a fine-tuned **Llama-3.1-8B-Instruct** model, the chatbot interprets dish descriptions, generates personalized nutrition advice, creates interactive conversations, and delivers clear, human-readable responses via an intuitive chat interface.

We utilize **FPT AI Studio** to streamline and automate the entire model development workflow:

* **[Model Fine-tuning](https://fptcloud.com/en/documents/model-fine-tuning/?doc=quick-start):** train and adapt the **Llama-3.1-8B-Instruct** model for domain-specific healthcare.
* **[Interactive Session](https://fptcloud.com/en/documents/model-testing-interactive-sessions/?doc=quick-start):** experiment with the model‚Äôs behavior in dialogue form, compare performance before and after fine-tuning, and deploy the fine-tuned version as an API for chatbot integration.
* **[Test Jobs](https://fptcloud.com/en/documents/model-testing-test-jobs/?doc=step-by-step):** benchmark model performance on a designated test set using multiple NLP metrics to ensure robustness and reliability.

In addition, **[Model Hub](https://fptcloud.com/en/documents/model-hub-2/?doc=quick-start)** and **[Data Hub](https://fptcloud.com/en/documents/data-hub/?doc=initial-setup)** are employed for efficient storage and management of large models and datasets.

## Pipeline

```mermaid
flowchart LR
  %% ==== Style definitions ====
  classDef local fill:#e8f4fd,stroke:#0366d6,stroke-width:2px,color:#000,font-weight:bold;
  classDef studio fill:#fff5e6,stroke:#ff9900,stroke-width:2px,color:#000,font-weight:bold;
  classDef neutral fill:#f8f9fa,stroke:#ccc,stroke-width:1px,color:#333;

  %% ==== Columns ====
  subgraph L["üè† Local Environment"]
    A1["1Ô∏è‚É£ Data Preparation<br/>- Collect food names"]:::local
    A2["2Ô∏è‚É£ Synthetic Data Generation<br/>- Teacher model: GPT-4o-mini<br/>- Generate conversations related to healthcare & nutrition"]:::local
    A3["6Ô∏è‚É£ Demo Application<br/>Chatbot Healthcare & Food"]:::local
  end

  subgraph R["‚òÅÔ∏è FPT AI Studio Platform"]
    B2["3Ô∏è‚É£ Model Training <br/>- Use Model Fine-tuning, Data Hub, Model Hub<br/>- Fine-tune Llama model"]:::studio
    B3["4Ô∏è‚É£ Model Evaluation <br/>- Use Test Jobs<br/>- Evaluate with NLP metrics"]:::studio
    B5["5Ô∏è‚É£ Model Deployment <br/>- Use Interactive Session<br/>- Deploy model ‚Üí API"]:::studio
  end

  %% ==== Flow between columns ====
  A1 --> A2
  A2 --> B2
  B2 --> B3
  B3 --> B5

  B5 -->|API endpoint| A3
  A3 -->|Send prompt with history| B5
  B5 -->|Return AI response | A3

```

The end-to-end pipeline for this project as shown on the above figure includes following stages:

1. **Data Preparation**: Prepare a list of ~50 regional foods with basic information.
2. **Synthetic Data Generation**: Use a teacher model (GPT-4o-mini) to create **detailed descriptions** and **healthcare-related dialogues** around each food.
3. **Model Training**: Fine-tuning the [meta-llama/Llama-3.1-8B-Instruct](https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct) model on the synthesized dataset using **Model Fine-tuning** in **FPT AI Studio platform**. 
In this step, we use **Data Hub** to easily manage training data and **Model Hub** to manage different versions of trained models.
4. **Model Evaluation**: Assessing the performance of the fine-tuned model with **Test Jobs**.
5. **Model Deployment**: Deploying the trained model as an API endpoint on FPT AI Studio for inference with **Interactive Session**.
6. **Demo Application**: An interactive **chat-based application** built with **Streamlit**, allowing users to explore foods and discuss nutrition interactively.

## 1. Data Preparation

We start with a curated list of **~50 regional foods**. Next, we generate **initial food descriptions** using GPT-4o-mini. These descriptions contain key nutritional information.

```python
VN_FOODS = [
    'B√°nh b√®o', 'B√°nh b·ªôt l·ªçc', 'B√°nh cƒÉn', 'B√°nh canh',
    'B√°nh ch∆∞ng', 'B√°nh cu·ªën', 'B√°nh ƒë√∫c',
    'B√°nh gi√≤', 'B√°nh kh·ªçt', 'B√°nh m√¨', 'B√°nh p√≠a', 'B√°nh t√©t',
    'B√°nh tr√°ng n∆∞·ªõng', 'B√°nh x√®o mi·ªÅn T√¢y', 'B√°nh x√®o mi·ªÅn Trung',
    'B√∫n b√≤ Hu·∫ø', 'B√∫n ƒë·∫≠u m·∫Øm t√¥m', 'B√∫n m·∫Øm', 'B√∫n ri√™u',
    'C√° kho t·ªô', 'Canh chua', 'Cao l·∫ßu', 'Ch√°o l√≤ng',
    'G·ªèi cu·ªën', 'H·ªß ti·∫øu', 'Nem chua', 'Ph·ªü', 'X√¥i x√©o',
    'B√∫n thang', 'B√∫n ·ªëc', 'Ch·∫£ c√° L√£ V·ªçng', 
    'Ph·ªü cu·ªën', 'B√°nh t√¥m H·ªì T√¢y', 'C∆°m t·∫•m',
    'Nem r√°n (ch·∫£ gi√≤)', 'B√∫n m·∫Øm n√™m', 
    'M√¨ Qu·∫£ng', 'B√°nh l·ªçc Hu·∫ø', 'C∆°m h·∫øn',
    'Ch√°o l∆∞∆°n', 'B√∫n th·ªãt n∆∞·ªõng', 'C√° l√≥c n∆∞·ªõng trui', 
    'B√°nh h·ªèi', 'X√¥i g·∫•c', 'Ch√® ba m√†u', 'B√°nh da l·ª£n',
    'L·∫©u m·∫Øm', 'B√°nh t√©t l√° c·∫©m', 'B√°nh m√¨ ch·∫£ c√°'
]
```

* **Refer**: [create description code](./src/get_infor_vn_food.py), [create description prompt](./prompts/teacher_prompts/introduce_vn_food.txt)

## 2. Synthetic Data Generation with gpt-4o-mini

To create a **rich conversational dataset**, we use GPT-4o-mini as a teacher model to produce dialogues around foods using food description of the previos stage, focusing on:
* **Healthcare & Nutrition**: calorie info, balanced diet, ingredient substitutions
* **Interactive Q&A**: questions about diet, allergies, health benefits

Prompt we used:
```txt
D·ª±a tr√™n m√¥ t·∫£ chi ti·∫øt v·ªÅ m√≥n ƒÉn Vi·ªát Nam sau ƒë√¢y (bao g·ªìm ngu·ªìn g·ªëc, c√°ch ch·∫ø bi·∫øn, h∆∞∆°ng v·ªã, th√†nh ph·∫ßn dinh d∆∞·ª°ng v√† √Ω nghƒ©a vƒÉn h√≥a,...), h√£y t·∫°o m·ªôt **ƒëo·∫°n h·ªôi tho·∫°i t·ª± nhi√™n gi·ªØa m·ªôt ng∆∞·ªùi d√πng v√† m·ªôt assistant chuy√™n v·ªÅ dinh d∆∞·ª°ng v√† s·ª©c kh·ªèe**.
M√¥ t·∫£ m√≥n ƒÉn:
"""
[INFO_VN_FOOD]
"""

Y√™u c·∫ßu:

1. H·ªôi tho·∫°i d√†i kho·∫£ng 8‚Äì12 l∆∞·ª£t n√≥i (turns).
2. Ng∆∞·ªùi d√πng c√≥ th·ªÉ h·ªèi v·ªÅ:
   * Th√¥ng tin b·∫•t k·ª≥ v·ªÅ m√≥n ƒÉn.
   * Gi√° tr·ªã dinh d∆∞·ª°ng c·ªßa m√≥n ƒÉn (calo, protein, ch·∫•t b√©o, carbohydrate, vitamin, kho√°ng ch·∫•t,...).
   * ·∫¢nh h∆∞·ªüng c·ªßa m√≥n ƒÉn t·ªõi c√°c b·ªánh l√Ω ph·ªï bi·∫øn (ti·ªÉu ƒë∆∞·ªùng, tim m·∫°ch, b√©o ph√¨, d·ªã ·ª©ng, huy·∫øt √°p, tim m·∫°ch, ung th∆∞, m·ª° m√°u, gan nhi·ªÖm m·ª°, vi√™m da, m·ª•n tr·ª©ng c√°,...).
   * G·ª£i √Ω c√°ch ƒÉn h·ª£p l√Ω cho ng∆∞·ªùi c√≥ t√¨nh tr·∫°ng s·ª©c kh·ªèe c·ª• th·ªÉ.
3. Assistant ph·∫£i tr·∫£ l·ªùi **c√≥ c∆° s·ªü, ch√≠nh x√°c, r√µ r√†ng**, v·ª´a cung c·∫•p th√¥ng tin dinh d∆∞·ª°ng, v·ª´a ƒë∆∞a l·ªùi khuy√™n h·ª£p l√Ω d·ª±a tr√™n t√¨nh tr·∫°ng s·ª©c kh·ªèe.
4. Gi·ªØ h·ªôi tho·∫°i **t·ª± nhi√™n, g·∫ßn g≈©i**, gi·ªëng nh∆∞ m·ªôt ng∆∞·ªùi d√πng th·∫≠t s·ª± ƒëang h·ªèi v√† m·ªôt chuy√™n gia tr·∫£ l·ªùi, kh√¥ng qu√° c·ª©ng nh·∫Øc hay khoa h·ªçc qu√° m·ª©c.
5. Bao g·ªìm √≠t nh·∫•t m·ªôt v√≠ d·ª• v·ªÅ c√°ch **thay ƒë·ªïi kh·∫©u ph·∫ßn ho·∫∑c ƒëi·ªÅu ch·ªânh m√≥n ƒÉn** ƒë·ªÉ ph√π h·ª£p v·ªõi t·ª´ng lo·∫°i b·ªánh l√Ω.

Xu·∫•t k·∫øt qu·∫£ d∆∞·ªõi d·∫°ng JSON list, m·ªói l∆∞·ª£t n√≥i l√† m·ªôt object v·ªõi key `"user"` v√† `"assistant"`. V√≠ d·ª• format:

[
  {
    "user": "User h·ªèi c√¢u n√†y...",
    "assistant": "Assistant tr·∫£ l·ªùi c√¢u n√†y..."
  },
  {
    "user": "User h·ªèi c√¢u kh√°c...",
    "assistant": "Assistant tr·∫£ l·ªùi c√¢u kh√°c..."
  }
]

B·∫Øt ƒë·∫ßu h·ªôi tho·∫°i t·ª´ c√¢u m·ªü ƒë·∫ßu c·ªßa ng∆∞·ªùi d√πng th·ªÉ hi·ªán s·ª± t√≤ m√≤ ho·∫∑c quan t√¢m v·ªÅ m√≥n ƒÉn n√†y.
```

After processing, here is a sample:
```json
{
    "conversations": [
      {
        "from": "human",
        "value": "Ch√†o b·∫°n! M√¨nh nghe n√≥i v·ªÅ b√∫n m·∫Øm, m·ªôt m√≥n ƒÉn r·∫•t n·ªïi ti·∫øng c·ªßa mi·ªÅn T√¢y. B·∫°n c√≥ th·ªÉ cho m√¨nh bi·∫øt th√™m v·ªÅ ngu·ªìn g·ªëc c·ªßa n√≥ kh√¥ng?"
      },
      {
        "from": "gpt",
        "value": "Ch√†o b·∫°n! B√∫n m·∫Øm c√≥ ngu·ªìn g·ªëc t·ª´ mi·ªÅn T√¢y Nam B·ªô, r·∫•t ƒë∆∞·ª£c y√™u th√≠ch ·ªü c√°c t·ªânh nh∆∞ S√≥c TrƒÉng, C·∫ßn Th∆° v√† B·∫°c Li√™u. M√≥n ƒÉn b·∫Øt ƒë·∫ßu xu·∫•t hi·ªán t·ª´ th·∫ø k·ª∑ 19, khi ng∆∞·ªùi d√¢n s·ª≠ d·ª•ng c√° c∆°m v√† h·∫£i s·∫£n t∆∞∆°i ƒë·ªÉ ch·∫ø bi·∫øn n∆∞·ªõc d√πng, t·∫°o n√™n h∆∞∆°ng v·ªã ƒë·∫≠m ƒë√†. ƒê√¢y c≈©ng l√† bi·ªÉu t∆∞·ª£ng vƒÉn h√≥a ·∫©m th·ª±c ƒë·∫∑c s·∫Øc c·ªßa v√πng s√¥ng n∆∞·ªõc."
      },
      {
        "from": "human",
        "value": "V·∫≠y b√∫n m·∫Øm c√≥ nh·ªØng th√†nh ph·∫ßn g√¨ v√† c√°ch ch·∫ø bi·∫øn nh∆∞ th·∫ø n√†o?"
      },
      {
        "from": "gpt",
        "value": "Nguy√™n li·ªáu ch√≠nh c·ªßa b√∫n m·∫Øm bao g·ªìm b√∫n t∆∞∆°i, m·∫Øm c√° (th∆∞·ªùng l√† m·∫Øm c√° linh ho·∫∑c m·∫Øm c√° basa), t√¥m, c√° l√≥c v√† c√°c lo·∫°i rau s·ªëng nh∆∞ rau mu·ªëng, gi√° ƒë·ªó, c√πng v·ªõi rau th∆°m nh∆∞ h√∫ng qu·∫ø, ng√≤ gai. ƒê·ªÉ ch·∫ø bi·∫øn, ng∆∞·ªùi ta n·∫•u m·∫Øm c√° v·ªõi n∆∞·ªõc, c√≥ th·ªÉ th√™m gia v·ªã nh∆∞ t·ªèi v√† ·ªõt, r·ªìi cho b√∫n v√†o t√¥, th√™m t√¥m, c√° v√† rau s·ªëng, tr∆∞·ªõc khi r∆∞·ªõi n∆∞·ªõc d√πng l√™n."
      },
      {
        "from": "human",
        "value": "M√¨nh r·∫•t th√≠ch ƒÉn ngon, nh∆∞ng c≈©ng quan t√¢m ƒë·∫øn ch·∫ø ƒë·ªô dinh d∆∞·ª°ng. B·∫°n c√≥ th·ªÉ cho m√¨nh bi·∫øt b√∫n m·∫Øm c√≥ bao nhi√™u calo v√† c√°c ch·∫•t dinh d∆∞·ª°ng kh√°c kh√¥ng?"
      },
      {
        "from": "gpt",
        "value": "T·∫•t nhi√™n! M·ªôt kh·∫©u ph·∫ßn b√∫n m·∫Øm kho·∫£ng 400-500 calo, t√πy v√†o l∆∞·ª£ng nguy√™n li·ªáu. Trong ƒë√≥ c√≥ kho·∫£ng 30g protein, ch·ªß y·∫øu t·ª´ t√¥m v√† c√°, 10g ch·∫•t b√©o t·ª´ h·∫£i s·∫£n v√† m·∫Øm, c√πng v·ªõi 60g carbohydrate t·ª´ b√∫n. N√≥ c≈©ng ch·ª©a nhi·ªÅu ch·∫•t x∆° t·ª´ rau s·ªëng v√† b·ªï sung vitamin A, C c√πng kho√°ng ch·∫•t t·ª´ h·∫£i s·∫£n."
      },
      {
        "from": "human",
        "value": "Nghe c√≥ v·∫ª h·ª£p l√Ω, nh∆∞ng n·∫øu m√¨nh b·ªã ti·ªÉu ƒë∆∞·ªùng th√¨ c√≥ th·ªÉ ƒÉn b√∫n m·∫Øm kh√¥ng? C√≥ c√°ch n√†o ƒÉn m√≥n n√†y m√† kh√¥ng l√†m tƒÉng ƒë∆∞·ªùng huy·∫øt kh√¥ng?"
      },
      {
        "from": "gpt",
        "value": "N·∫øu b·∫°n b·ªã ti·ªÉu ƒë∆∞·ªùng, b·∫°n c√≥ th·ªÉ v·∫´n th∆∞·ªüng th·ª©c b√∫n m·∫Øm nh∆∞ng c·∫ßn ƒëi·ªÅu ch·ªânh kh·∫©u ph·∫ßn. B·∫°n n√™n gi·∫£m l∆∞·ª£ng b√∫n ƒë·ªÉ gi·∫£m carbohydrate v√† tƒÉng c∆∞·ªùng rau s·ªëng. Ngo√†i ra, b·∫°n c√≥ th·ªÉ ch·ªçn lo·∫°i m·∫Øm √≠t mu·ªëi v√† h·∫°n ch·∫ø n∆∞·ªõc d√πng ƒë·ªÉ kh√¥ng b·ªã tƒÉng huy·∫øt √°p. H√£y nh·ªõ theo d√µi ƒë∆∞·ªùng huy·∫øt sau khi ƒÉn ƒë·ªÉ xem ph·∫£n ·ª©ng c·ªßa c∆° th·ªÉ."
      },
      {
        "from": "human",
        "value": "C√≥ c√°ch n√†o kh√°c ƒë·ªÉ b√∫n m·∫Øm ph√π h·ª£p h∆°n cho ng∆∞·ªùi nh∆∞ m√¨nh kh√¥ng?"
      },
      {
        "from": "gpt",
        "value": "C√≥, b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng b√∫n gi·∫£ (nh∆∞ b√∫n t·ª´ ƒë·∫≠u xanh ho·∫∑c b√∫n t·ª´ rau c·ªß) ƒë·ªÉ gi·∫£m l∆∞·ª£ng carbohydrate. Ngo√†i ra, c√≥ th·ªÉ th√™m nhi·ªÅu rau s·ªëng h∆°n, c√≥ th·ªÉ ngo√†i rau mu·ªëng v√† gi√° ƒë·ªó, b·∫°n th·ª≠ th√™m c√°c lo·∫°i rau xanh nh∆∞ c·∫£i th√¨a ho·∫∑c m·ªìng t∆°i ƒë·ªÉ tƒÉng ch·∫•t x∆° v√† vitamin. ƒÇn c√πng v·ªõi m·ªôt ch√∫t chanh v√† ·ªõt t∆∞∆°i c≈©ng gi√∫p tƒÉng h∆∞∆°ng v·ªã m√† kh√¥ng l√†m tƒÉng calo."
      },
      {
        "from": "human",
        "value": "Th√∫ v·ªã qu√°! B√∫n m·∫Øm c√≥ ·∫£nh h∆∞·ªüng g√¨ ƒë·∫øn s·ª©c kh·ªèe tim m·∫°ch kh√¥ng?"
      },
      {
        "from": "gpt",
        "value": "B√∫n m·∫Øm c√≥ ch·ª©a ch·∫•t b√©o t·ª´ h·∫£i s·∫£n v√† m·∫Øm, n√™n n·∫øu b·∫°n c√≥ v·∫•n ƒë·ªÅ v·ªÅ tim m·∫°ch, h√£y ch√∫ √Ω ƒë·∫øn l∆∞·ª£ng m·∫Øm s·ª≠ d·ª•ng. H·∫°n ch·∫ø l∆∞·ª£ng mu·ªëi v√† ch·∫•t b√©o saturates c√≥ trong m·∫Øm v√† h·∫£i s·∫£n. B·∫°n n√™n ch·ªçn c√° nh∆∞ c√° l√≥c ho·∫∑c t√¥m t∆∞∆°i ƒë·ªÉ ƒë∆∞a v√†o m√≥n ƒÉn, v√¨ ch√∫ng c√≥ ch·ª©a omega-3, t·ªët cho tim m·∫°ch. Theo d√µi ph·∫ßn ƒÉn v√† h·∫°n ch·∫ø m·∫Øm c√≥ th·ªÉ t·ªët cho b·∫°n."
      },
      {
        "from": "human",
        "value": "V·∫≠y n·∫øu m√¨nh mu·ªën gi·∫£m b√©o th√¨ sao? B√∫n m·∫Øm c√≥ ph·∫£i l√† m√≥n ƒÉn t·ªët cho k·∫ø ho·∫°ch gi·∫£m c√¢n kh√¥ng?"
      },
      {
        "from": "gpt",
        "value": "B√∫n m·∫Øm c√≥ th·ªÉ kh√¥ng ph·∫£i l√† l·ª±a ch·ªçn t·ªëi ∆∞u n·∫øu b·∫°n ƒëang gi·∫£m c√¢n v√¨ n√≥ c√≥ ch·ª©a kh√° nhi·ªÅu calo, ƒë·∫∑c bi·ªát n·∫øu ƒÉn v·ªõi nhi·ªÅu h·∫£i s·∫£n v√† m·∫Øm. Tuy nhi√™n, n·∫øu b·∫°n gi·∫£m kh·∫©u ph·∫ßn b√∫n, tƒÉng c∆∞·ªùng rau s·ªëng v√† ch·ªçn nh·ªØng nguy√™n li·ªáu th·∫•p calo, th√¨ b√∫n m·∫Øm v·∫´n c√≥ th·ªÉ l√† m·ªôt ph·∫ßn c·ªßa ch·∫ø ƒë·ªô ƒÉn gi·∫£m c√¢n. H√£y ch√∫ √Ω ƒë·∫øn kh·∫©u ph·∫ßn v√† v·∫≠n ƒë·ªông th·ªÉ ch·∫•t ƒë·ªÉ duy tr√¨ nƒÉng l∆∞·ª£ng c√¢n b·∫±ng."
      },
      {
        "from": "human",
        "value": "C·∫£m ∆°n b·∫°n r·∫•t nhi·ªÅu v√¨ nh·ªØng th√¥ng tin h·ªØu √≠ch! M√¨nh r·∫•t h√°o h·ª©c th·ª≠ b√∫n m·∫Øm l·∫ßn ƒë·∫ßu ti√™n."
      },
      {
        "from": "gpt",
        "value": "R·∫•t vui v√¨ ƒë∆∞·ª£c gi√∫p ƒë·ª° b·∫°n! Khi th·ª≠ b√∫n m·∫Øm, h√£y nh·ªõ th√™m ch√∫t chanh v√† ·ªõt ƒë·ªÉ tƒÉng h∆∞∆°ng v·ªã nh√©. Ch√∫c b·∫°n c√≥ nh·ªØng tr·∫£i nghi·ªám ·∫©m th·ª±c tuy·ªát v·ªùi v√† lu√¥n chƒÉm s√≥c s·ª©c kh·ªèe t·ªët!"
      }
    ]
}
```

* **Refer**: [synthesize_data code](./src/create_conversation.py), [process_synthesized_data code](./src/preprocess_synthesized_data.py), [split_data code](./src/split_and_merge.py), [prompt](./prompts/teacher_prompts/create_healthcare_conversation.txt)

## 3. Model Training on FPT AI Studio

With our synthetic dataset ready, the next step was to fine-tune a smaller, more efficient model that could serve as an intelligent assistant. We fine-tuned the model using the LoRA technique.

* **Model**: [meta-llama/Llama-3.1-8B-Instruct](https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct).
* **Data**: The synthetically generated dataset: [data/final_data/healthcare_and_vn_food](./data/final_data/healthcare_and_vn_food)
    * [Train set](./data/final_data/chat/train_no_json.json): 1,916 samples
    * [Val set](./data/final_data/chat/val_no_json.json): 110 samples
    * [Test set](./data/final_data/chat/test_no_json.json): 110 samples


    Based on the data distribution we have collected, we set **max_sequence_length = 1024**.
    ![number_of_tokens_distribution](./images/hc_train_token_distribution.png)
    
* **Hyper-parameters**:
    ```
    {
        "batch_size": 32,
        "checkpoint_steps": 1000,
        "checkpoint_strategy": "epoch",
        "disable_gradient_checkpointing": false,
        "distributed_backend": "ddp",
        "dpo_label_smoothing": 0,
        "epochs": 3,
        "eval_steps": 1000,
        "eval_strategy": "epoch",
        "flash_attention_v2": true,
        "full_determinism": false,
        "gradient_accumulation_steps": 2,
        "learning_rate": 0.00001,
        "liger_kernel": true,
        "logging_steps": 10,
        "lora_alpha": 32,
        "lora_dropout": 0.05,
        "lora_rank": 16,
        "lr_scheduler_type": "linear",
        "lr_warmup_steps": 0,
        "lr_warmup_ratio": 0.1,
        "max_grad_norm": 1,
        "max_sequence_length": 1024,
        "merge_adapter": true,
        "mixed_precision": "bf16",
        "number_of_checkpoints": 1,
        "optimizer": "adamw",
        "pref_beta": 0.1,
        "pref_ftx": 0,
        "pref_loss": "sigmoid",
        "quantization_bit": "none",
        "resume_from_checkpoint": false,
        "save_best_checkpoint": false,
        "seed": 1309,
        "simpo_gamma": 0.5,
        "target_modules": "all-linear",
        "training_type": "lora",
        "unsloth_gradient_checkpointing": false,
        "weight_decay": 0.1,
        "zero_stage": 1
    }
    ```
* **Infrastructure**: We trained the model on **1 H100 GPUs**, leveraging **FlashAttention 2** and **Liger kernels** to accelerate the training process. The global batch size was set to 64.

* **Training**:
    Create pipeline and start training.
    ![create_pipeline](./images/pipeline.png)

    During the model training process, we can monitor the loss values and other related metrics in the **Model metrics** section.
    <p align="center">
    <img src="./images/train_loss.png" alt="train_loss" width="45%"/>
    <img src="./images/eval_loss.png" alt="eval_loss" width="45%"/>
    </p>

    In addition, we can observe the system-related metrics in the **System metrics** section.
    ![system_metric](./images/system_metric.png)


* The model, after being trained, is saved in the **Private Model** section of the **Model Hub**. Users **can download** it or use it **directly with other services** such as Interactive Session or Test Jobs.
![private_model](./images/private_model.png)

* **Training** took 21 minutes, with **GPU usage** lasting 18 minutes. **The cost** of using the fine-tune model is **~$0.693**.

  Explanation of Costs: At **FPT AI Studio**, we charge **$2.31 per GPU-hour**. Importantly, we only charge for **actual GPU usage time** and time spent on tasks such as **model downloading, data downloading, data tokenization,** and **pushing data to the Model Hub** is **not included** in the calculation. 
<!-- * **Step-by-step**: -->

## 4. Model Evaluation

After training, the model's performance was evaluated to ensure it met the required accuracy and efficiency. We use **FPT AI Studio's Test Jobs** with NLP metrics to evaluate the model on the **test set** in order to compare the model before and after fine-tuning.

![test-job](./images/test-job.png)

* **Result**:
    | Model            | Fuzzy Match | BLEU     | ROUGE-1  | ROUGE-2  | ROUGE-L  | ROUGE-Lsum |
    |------------------|--------------|----------|----------|----------|-----------|-------------|
    | **Finetuned Llama-3.1-8B-Instruct** |  **0.458633**    | 0.032079 | **0.634257** | **0.333767** | **0.412934** | **0.41459**   |
    | **Base Llama-3.1-8B-Instruct**      | 0.387204     | **0.05343** | 0.535179 | 0.270515 | 0.349951 | 0.365346    |


## 5. Model Deployment

The fine-tuned model was deployed on **FPT AI Studio's Interactive Session**. This made the model accessible via an API endpoint, allowing our Streamlit application to send prompt. In addition, we can chat directly on the **Interactive Session** interface.
![interactive_session](./images/interactive_session_.png)

<!-- * **Step-by-step**: -->

## 6. Demo Application

The final piece of the project is the Streamlit dashboard, which provides a user-friendly interface for talking directly to my assistant.

### How to run the demo

To run this demo on your local machine, follow these steps:

1. **Clone the repository:**
    ```bash
    git clone https://github.com/fpt-corp/ai-studio.git
    cd tutorials/healthcare-and-food-chatbot
    ```

2. **Install the required libraries:**
    ```bash
    pip install -r requirements.txt
    ```

3. **Set up environment variables:**
    Take the API endpoint and credentials on FPT AI Studio as shown on above firgure, you will need to configure the following environment variables in `scripts/run_app.sh`:
    ```
    export TOKEN="BEARER_TOKEN"
    export ENDPOINT_URL="API_ENDPOINT"
    export MODEL="MODEL_ID"
    ```

4. **Run the Streamlit application:**
    ```bash
    bash scripts/run_app.sh
    ```

    **Streamlit demo results integrating the fine-tuned model:**
    ![streamlit_finetuned_model](./images/demo_llama3_fine-tuned.png)